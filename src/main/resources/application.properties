spring.application.name=incident-tracker

# Configuration Groq (LLM gratuit et rapide)
langchain4j.open-ai.chat-model.base-url=https://api.groq.com/openai/v1
langchain4j.open-ai.chat-model.api-key=${GROQ_API_KEY}
langchain4j.open-ai.chat-model.model-name=llama-3.3-70b-versatile
langchain4j.open-ai.chat-model.temperature=0.3
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
